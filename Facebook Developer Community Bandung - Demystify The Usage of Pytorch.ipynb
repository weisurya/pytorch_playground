{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching from ND Array > Pytorch Tensor -> ND Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15830809,  0.49762122,  0.09137921],\n",
       "       [-2.3819232 ,  0.47606143, -1.99124683],\n",
       "       [-1.69857664,  0.14952153, -0.05160555],\n",
       "       [ 0.0166688 ,  0.89088917, -0.47966096],\n",
       "       [ 0.16908941,  1.43305621, -0.83057521]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomArray = np.random.randn(5, 3)\n",
    "randomArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1583,  0.4976,  0.0914],\n",
       "        [-2.3819,  0.4761, -1.9912],\n",
       "        [-1.6986,  0.1495, -0.0516],\n",
       "        [ 0.0167,  0.8909, -0.4797],\n",
       "        [ 0.1691,  1.4331, -0.8306]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomTensor = torch.from_numpy(randomArray)\n",
    "randomTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15830809,  0.49762122,  0.09137921],\n",
       "       [-2.3819232 ,  0.47606143, -1.99124683],\n",
       "       [-1.69857664,  0.14952153, -0.05160555],\n",
       "       [ 0.0166688 ,  0.89088917, -0.47966096],\n",
       "       [ 0.16908941,  1.43305621, -0.83057521]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomTensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switching from using CPU - GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_0 = torch.device('cuda:0')\n",
    "cuda_2 = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.rand(10000, 10000, device=cpu)\n",
    "x1 = torch.rand(10000, 10000, device=cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timelapse:  9.464088493827148\n"
     ]
    }
   ],
   "source": [
    "start_cpu = timeit.default_timer()\n",
    "\n",
    "x1.matmul(w1)\n",
    "\n",
    "end_cpu = timeit.default_timer()\n",
    "print('Timelapse: ', end_cpu- start_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timelapse:  0.5371105185184888\n"
     ]
    }
   ],
   "source": [
    "start_gpu = timeit.default_timer()\n",
    "\n",
    "x1 = x1.cuda()\n",
    "w1 = w1.cuda()\n",
    "\n",
    "x1.matmul(w1)\n",
    "\n",
    "end_gpu = timeit.default_timer()\n",
    "print('Timelapse: ', end_gpu - start_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference:  18.0 x faster\n"
     ]
    }
   ],
   "source": [
    "print('Difference: ', np.round((end_cpu- start_cpu)/(end_gpu - start_gpu), 0),'x faster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# By default, requires_grad is set to False\n",
    "x = torch.randn(5, 5)\n",
    "y = torch.randn(5, 5)\n",
    "z = torch.randn((5, 5), requires_grad=True)\n",
    "\n",
    "result = x + y\n",
    "print(result.requires_grad)\n",
    "\n",
    "second_result = result + z\n",
    "print(second_result.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "print(\"Before: \", input.grad)\n",
    "\n",
    "output = input.mean()\n",
    "output.backward()\n",
    "\n",
    "print(\"After: \", input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Object Oriented Programming Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = [128, 64]\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "        self.fc2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.fc3 = nn.Linear(hidden_size[1], output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oop_model = Network(input_size=input_size, \n",
    "                    hidden_size=hidden_size, \n",
    "                    output_size=output_size)\n",
    "oop_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, weights and bias are automatically filled up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0334,  0.0349,  0.0099,  ...,  0.0143, -0.0273, -0.0090],\n",
      "        [-0.0218, -0.0161, -0.0073,  ..., -0.0026,  0.0082,  0.0172],\n",
      "        [ 0.0113, -0.0095,  0.0001,  ..., -0.0025, -0.0066,  0.0297],\n",
      "        ...,\n",
      "        [ 0.0303,  0.0197,  0.0251,  ...,  0.0280, -0.0012,  0.0355],\n",
      "        [ 0.0238, -0.0035,  0.0249,  ..., -0.0151,  0.0099, -0.0339],\n",
      "        [-0.0237, -0.0225,  0.0079,  ...,  0.0066,  0.0294,  0.0161]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0317,  0.0100, -0.0192, -0.0028, -0.0024,  0.0003,  0.0218,  0.0340,\n",
      "         0.0087, -0.0174,  0.0250, -0.0033, -0.0197,  0.0130, -0.0136,  0.0229,\n",
      "        -0.0150, -0.0104, -0.0188,  0.0048, -0.0349, -0.0313,  0.0147,  0.0038,\n",
      "         0.0222,  0.0204,  0.0070, -0.0352,  0.0320, -0.0268,  0.0100, -0.0078,\n",
      "         0.0132,  0.0146, -0.0053,  0.0245,  0.0085,  0.0227, -0.0203,  0.0186,\n",
      "        -0.0038, -0.0208, -0.0135,  0.0206,  0.0192, -0.0245,  0.0148, -0.0251,\n",
      "        -0.0025, -0.0100, -0.0055, -0.0072, -0.0256, -0.0339, -0.0124, -0.0044,\n",
      "        -0.0134,  0.0241, -0.0270, -0.0327, -0.0285,  0.0357,  0.0118, -0.0117,\n",
      "         0.0357, -0.0255,  0.0062,  0.0157,  0.0262,  0.0194, -0.0298, -0.0322,\n",
      "        -0.0027,  0.0061, -0.0023, -0.0168, -0.0338,  0.0210, -0.0039, -0.0087,\n",
      "         0.0005,  0.0009, -0.0040, -0.0244,  0.0249, -0.0155, -0.0121,  0.0149,\n",
      "         0.0295,  0.0218, -0.0096, -0.0075, -0.0023, -0.0025, -0.0175, -0.0041,\n",
      "        -0.0208, -0.0249,  0.0292,  0.0257, -0.0307,  0.0227, -0.0046, -0.0173,\n",
      "         0.0039,  0.0256, -0.0012, -0.0230,  0.0287,  0.0045, -0.0140,  0.0054,\n",
      "         0.0067, -0.0215, -0.0124, -0.0093,  0.0310, -0.0090, -0.0226, -0.0276,\n",
      "        -0.0168, -0.0211, -0.0165,  0.0350, -0.0155, -0.0147,  0.0072,  0.0208],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(oop_model.fc1.weight)\n",
    "print(oop_model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also modify the value of these tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set bias to be zero\n",
    "oop_model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0069, -0.0008, -0.0109,  ..., -0.0039,  0.0123, -0.0008],\n",
       "        [-0.0027,  0.0198, -0.0050,  ...,  0.0021,  0.0011, -0.0044],\n",
       "        [ 0.0034,  0.0233,  0.0141,  ...,  0.0094, -0.0049,  0.0153],\n",
       "        ...,\n",
       "        [-0.0195,  0.0073,  0.0061,  ...,  0.0207, -0.0077, -0.0110],\n",
       "        [-0.0055,  0.0001, -0.0076,  ...,  0.0099,  0.0087,  0.0060],\n",
       "        [-0.0041, -0.0229,  0.0102,  ..., -0.0013,  0.0103,  0.0014]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set weight into normal distribution with standard deviation of .01\n",
    "oop_model.fc1.weight.data.normal_(std=.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (5): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_model = nn.Sequential(nn.Linear(in_features=input_size, out_features=hidden_size[0]),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(in_features=hidden_size[0], out_features=hidden_size[1]),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(in_features=hidden_size[1], out_features=output_size),\n",
    "                                 nn.Softmax(dim=1))\n",
    "\n",
    "sequential_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Style - Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_sequential_model = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(input_size, hidden_size[0])),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(hidden_size[0], hidden_size[1])),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('output', nn.Linear(hidden_size[1], output_size)),\n",
    "    ('softmax', nn.Softmax(dim=1))\n",
    "]))\n",
    "\n",
    "alt_sequential_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pick up any layer easily like you used to code in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "ReLU()\n"
     ]
    }
   ],
   "source": [
    "print(sequential_model[0])\n",
    "print(sequential_model[1])\n",
    "\n",
    "print(oop_model.fc1)\n",
    "print(oop_model.fc2)\n",
    "\n",
    "print(alt_sequential_model.fc2)\n",
    "print(alt_sequential_model.relu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning by Using Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert from Pytorch to another framework by using ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
